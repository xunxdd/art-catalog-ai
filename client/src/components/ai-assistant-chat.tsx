import { useState, useRef, useEffect } from "react";
import { Dialog, DialogContent, DialogHeader, DialogTitle } from "@/components/ui/dialog";
import { Button } from "@/components/ui/button";
import { Input } from "@/components/ui/input";
import { Card, CardContent } from "@/components/ui/card";
import { Badge } from "@/components/ui/badge";
import { Bot, User, Camera, Upload, Send, Mic, MicOff, Image, X, Trash2, Volume2, VolumeX } from "lucide-react";
import { useToast } from "@/hooks/use-toast";
import { useMutation, useQueryClient } from "@tanstack/react-query";
import { apiRequest } from "@/lib/queryClient";

interface AIAssistantChatProps {
  open: boolean;
  onOpenChange: (open: boolean) => void;
}

interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  actions?: Array<{
    label: string;
    action: () => void;
    variant?: 'default' | 'outline';
  }>;
}

export function AIAssistantChat({ open, onOpenChange }: AIAssistantChatProps) {
  const { toast } = useToast();
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState("");
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [voiceEnabled, setVoiceEnabled] = useState(true);
  const [currentStep, setCurrentStep] = useState<'greeting' | 'photo_tips' | 'uploading' | 'analyzing' | 'complete'>('greeting');
  const [uploadedFiles, setUploadedFiles] = useState<File[]>([]);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);
  const recognitionRef = useRef<any>(null);
  const queryClient = useQueryClient();

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  useEffect(() => {
    if (open && messages.length === 0) {
      // Initialize conversation
      addAssistantMessage(
        "ðŸ‘‹ Hi! I'm your AI Art Assistant. I'll guide you through photographing and cataloging your artwork. Ready to get started?",
        [
          { label: "Yes, let's start!", action: () => startPhotoGuidance(), variant: 'default' },
          { label: "Tell me about best practices first", action: () => showPhotoTips(), variant: 'outline' }
        ]
      );
    }
  }, [open, messages.length]);

  const speakText = (text: string) => {
    if (!voiceEnabled || !('speechSynthesis' in window)) return;
    
    // Stop any current speech
    window.speechSynthesis.cancel();
    
    // Clean text for speech (remove markdown and emojis)
    const cleanText = text
      .replace(/[#*`]/g, '') // Remove markdown
      .replace(/[ðŸŽ¨ðŸ–Œï¸ðŸ’µâ­ðŸŽ‰ðŸ”ðŸ’°ðŸ“¸âœ¨âŒðŸš€ðŸ“ðŸ·ï¸ðŸ‘‹ðŸ’¡âœ…âŒðŸ“ðŸŽ¯]/g, '') // Remove emojis
      .replace(/\n\n/g, '. ') // Replace double newlines with periods
      .replace(/\n/g, ' ') // Replace single newlines with spaces
      .substring(0, 200); // Limit length for better speech
    
    const utterance = new SpeechSynthesisUtterance(cleanText);
    utterance.rate = 0.9;
    utterance.pitch = 1.0;
    utterance.volume = 0.8;
    
    utterance.onstart = () => setIsSpeaking(true);
    utterance.onend = () => setIsSpeaking(false);
    utterance.onerror = () => setIsSpeaking(false);
    
    window.speechSynthesis.speak(utterance);
  };

  const addAssistantMessage = (content: string, actions?: Array<{label: string; action: () => void; variant?: 'default' | 'outline'}>) => {
    const message: Message = {
      id: Date.now().toString(),
      role: 'assistant',
      content,
      timestamp: new Date(),
      actions
    };
    setMessages(prev => [...prev, message]);
    
    // Speak the message after a short delay
    setTimeout(() => speakText(content), 500);
  };

  const addUserMessage = (content: string) => {
    const message: Message = {
      id: Date.now().toString(),
      role: 'user',
      content,
      timestamp: new Date(),
    };
    setMessages(prev => [...prev, message]);
  };

  const startPhotoGuidance = () => {
    setCurrentStep('photo_tips');
    addUserMessage("Yes, let's start!");
    addAssistantMessage(
      "Perfect! Let's create amazing photos of your artwork. Here's what you'll need:\n\nðŸ“¸ **Equipment**: Phone camera or DSLR\nðŸ’¡ **Lighting**: Natural daylight or soft, even lighting\nðŸ“ **Setup**: Flat surface, artwork laid flat or hung straight\nðŸŽ¯ **Angles**: I'll guide you through multiple shots",
      [
        { label: "I'm ready to take photos", action: () => startPhotoSession(), variant: 'default' },
        { label: "Tell me more about lighting", action: () => explainLighting(), variant: 'outline' }
      ]
    );
  };

  const showPhotoTips = () => {
    addUserMessage("Tell me about best practices first");
    addAssistantMessage(
      "Great question! Here are professional artwork photography tips:\n\nðŸŽ¨ **Professional Approach**:\nâ€¢ Take 5-7 shots: full artwork, close-ups of texture, signature, and corners\nâ€¢ Use consistent lighting to avoid color shifts\nâ€¢ Shoot straight-on to prevent distortion\nâ€¢ Include a color reference card if possible\n\nðŸ“± **Phone Photography**:\nâ€¢ Clean your lens first\nâ€¢ Use HDR mode for better dynamic range\nâ€¢ Avoid flash - use window light instead\nâ€¢ Take multiple angles for AI analysis",
      [
        { label: "Got it, let's start shooting", action: () => startPhotoSession(), variant: 'default' }
      ]
    );
  };

  const explainLighting = () => {
    addUserMessage("Tell me more about lighting");
    addAssistantMessage(
      "ðŸ’¡ **Lighting Setup Tips**:\n\nâœ… **Best Options**:\nâ€¢ North-facing window (soft, consistent light)\nâ€¢ Overcast day outdoors (natural diffusion)\nâ€¢ Two desk lamps at 45Â° angles\n\nâŒ **Avoid**:\nâ€¢ Direct sunlight (creates harsh shadows)\nâ€¢ Mixed light sources (color temperature issues)\nâ€¢ Flash (creates glare and uneven lighting)\n\nðŸŽ¯ **Pro Tip**: Take a test shot first - colors should look natural and details should be clearly visible in shadows.",
      [
        { label: "Perfect, I'm ready now", action: () => startPhotoSession(), variant: 'default' }
      ]
    );
  };

  const startPhotoSession = () => {
    setCurrentStep('uploading');
    addUserMessage("I'm ready to take photos");
    addAssistantMessage(
      "Excellent! Let's capture your artwork. I recommend taking these shots:\n\n1ï¸âƒ£ **Full artwork** - entire piece, straight-on\n2ï¸âƒ£ **Detail shots** - interesting textures or techniques\n3ï¸âƒ£ **Signature** - artist signature if visible\n4ï¸âƒ£ **Corner/edge** - to show condition\n\nStart with the full artwork shot. When ready, click 'Upload Photos' below:",
      [
        { label: "Upload Photos", action: () => triggerFileUpload(), variant: 'default' },
        { label: "Use Camera", action: () => triggerCameraCapture(), variant: 'outline' }
      ]
    );
  };

  const triggerFileUpload = () => {
    fileInputRef.current?.click();
  };

  const triggerCameraCapture = () => {
    // For mobile devices, this will open the camera
    const input = document.createElement('input');
    input.type = 'file';
    input.accept = 'image/*';
    input.setAttribute('capture', 'environment');
    input.onchange = (e) => {
      const target = e.target as HTMLInputElement;
      if (target.files && target.files.length > 0) {
        processFiles(Array.from(target.files));
      }
    };
    input.click();
  };

  const handleFileSelect = (event: React.ChangeEvent<HTMLInputElement>) => {
    const files = event.target.files;
    if (files && files.length > 0) {
      processFiles(Array.from(files));
    }
  };

  const uploadMutation = useMutation({
    mutationFn: async (file: File) => {
      const formData = new FormData();
      formData.append('artwork', file);
      const response = await apiRequest("POST", "/api/artworks/upload", formData);
      return response.json();
    },
    onSuccess: (data) => {
      queryClient.invalidateQueries({ queryKey: ["/api/user/artworks"] });
      queryClient.invalidateQueries({ queryKey: ["/api/artworks/recent"] });
      
      addAssistantMessage(
        `âœ¨ **Analysis Complete!** Here's what I found:\n\nðŸŽ¨ **Title**: ${data.title}\nðŸ–Œï¸ **Medium**: ${data.medium || 'Analyzing...'}\nðŸ’µ **Suggested Price**: $${data.suggestedPrice || 'Calculating...'}\nâ­ **Condition**: ${data.condition || 'Excellent'}\n\nI've created your catalog entry with professional descriptions. What would you like to do next?`,
        [
          { label: "Create Marketplace Listing", action: () => handleCreateListing(), variant: 'default' },
          { label: "Edit Details", action: () => handleEditDetails(), variant: 'outline' },
          { label: "Upload Another Artwork", action: () => resetConversation(), variant: 'outline' }
        ]
      );
      setCurrentStep('complete');
    },
    onError: (error: any) => {
      addAssistantMessage(
        `âŒ **Upload Failed**: ${error.message}\n\nPlease try again with a different image or check your connection.`,
        [
          { label: "Try Again", action: () => setCurrentStep('uploading'), variant: 'default' }
        ]
      );
    }
  });

  const processFiles = (files: File[]) => {
    setUploadedFiles(files);
    setCurrentStep('analyzing');
    addUserMessage(`Selected ${files.length} photo${files.length > 1 ? 's' : ''}`);
    
    addAssistantMessage(
      `ðŸŽ‰ Perfect! I can see your ${files.length} photo${files.length > 1 ? 's' : ''}. Ready to upload and analyze?`,
      [
        { label: "Upload & Analyze", action: () => startUpload(), variant: 'default' },
        { label: "Remove Photos", action: () => clearFiles(), variant: 'outline' }
      ]
    );
  };

  const startUpload = () => {
    if (uploadedFiles.length > 0) {
      addAssistantMessage(
        `ðŸš€ **Uploading and analyzing** your artwork...\n\nðŸ” **AI Analysis includes**:\nâ€¢ Style and medium identification\nâ€¢ Market value estimation\nâ€¢ Professional description generation\nâ€¢ Category and tag suggestions\n\nThis usually takes 10-30 seconds...`,
        []
      );
      
      // Upload the first file (main artwork photo)
      uploadMutation.mutate(uploadedFiles[0]);
    }
  };

  const clearFiles = () => {
    setUploadedFiles([]);
    setCurrentStep('uploading');
    addAssistantMessage(
      "ðŸ“¸ **Photos cleared!** Ready to take new photos of your artwork.",
      [
        { label: "Upload Photos", action: () => triggerFileUpload(), variant: 'default' },
        { label: "Use Camera", action: () => triggerCameraCapture(), variant: 'outline' }
      ]
    );
  };

  const completeAnalysis = () => {
    setCurrentStep('complete');
    addAssistantMessage(
      "âœ¨ **Analysis Complete!** Here's what I found:\n\nðŸŽ¨ **Style**: Contemporary Digital Art\nðŸ–Œï¸ **Medium**: Digital painting\nðŸ’µ **Suggested Price**: $150-200\nâ­ **Condition**: Excellent\n\nI've created your catalog entry with professional descriptions. What would you like to do next?",
      [
        { label: "Create Marketplace Listing", action: () => handleCreateListing(), variant: 'default' },
        { label: "Edit Details", action: () => handleEditDetails(), variant: 'outline' },
        { label: "Upload Another Artwork", action: () => resetConversation(), variant: 'outline' }
      ]
    );
  };

  const handleCreateListing = () => {
    addUserMessage("Create Marketplace Listing");
    addAssistantMessage(
      "ðŸš€ **Ready to sell!** I'll help you create listings on:\n\nâ€¢ **Etsy** - Handmade marketplace\nâ€¢ **Saatchi Art** - Contemporary art platform\nâ€¢ **Your Website** - Direct sales\n\nWhich platform interests you most?",
      [
        { label: "Show me all options", action: () => openMarketplaceDialog(), variant: 'default' }
      ]
    );
  };

  const handleEditDetails = () => {
    addUserMessage("Edit Details");
    addAssistantMessage(
      "ðŸ“ **Edit Mode**: You can adjust:\n\nâ€¢ Title and description\nâ€¢ Pricing and dimensions\nâ€¢ Medium and style tags\nâ€¢ Artist information\n\nI'll open the editing interface for you.",
      [
        { label: "Open Editor", action: () => openEditDialog(), variant: 'default' }
      ]
    );
  };

  const resetConversation = () => {
    setCurrentStep('greeting');
    setMessages([]);
    addAssistantMessage(
      "ðŸŽ¨ **Ready for another artwork!** Let's catalog your next piece. Same process - I'll guide you through the photography and analysis.",
      [
        { label: "Start Photo Session", action: () => startPhotoSession(), variant: 'default' }
      ]
    );
  };

  const openMarketplaceDialog = () => {
    toast({
      title: "Opening Marketplace Options",
      description: "Marketplace listing dialog will open...",
    });
    // This would trigger the marketplace listing dialog
  };

  const openEditDialog = () => {
    toast({
      title: "Opening Editor",
      description: "Artwork edit dialog will open...",
    });
    // This would trigger the edit dialog
  };

  const handleSendMessage = () => {
    if (!input.trim()) return;
    
    addUserMessage(input);
    
    // Simple AI responses based on input
    setTimeout(() => {
      if (input.toLowerCase().includes('help') || input.toLowerCase().includes('how')) {
        addAssistantMessage(
          "I'm here to help! I can guide you through:\n\nðŸ“¸ **Photography**: Best practices and lighting\nðŸ¤– **AI Analysis**: Automatic artwork identification\nðŸ’° **Pricing**: Market value estimation\nðŸ›’ **Selling**: Marketplace listing creation\n\nWhat specifically would you like help with?",
          [
            { label: "Start Photo Session", action: () => startPhotoSession(), variant: 'default' }
          ]
        );
      } else if (input.toLowerCase().includes('price') || input.toLowerCase().includes('value')) {
        addAssistantMessage(
          "ðŸ’° **Pricing Insights**: I analyze your artwork using:\n\nâ€¢ Similar works sold recently\nâ€¢ Artist recognition and style\nâ€¢ Medium and technique complexity\nâ€¢ Current market trends\n\nTo get an accurate price estimate, I'll need to see your artwork first. Ready to upload?",
          [
            { label: "Upload for Analysis", action: () => startPhotoSession(), variant: 'default' }
          ]
        );
      } else {
        addAssistantMessage(
          "I understand you're interested in artwork cataloging! I can help you photograph, analyze, and list your art for sale. Would you like to start with a photo session?",
          [
            { label: "Yes, let's start", action: () => startPhotoSession(), variant: 'default' }
          ]
        );
      }
    }, 1000);
    
    setInput("");
  };

  const initSpeechRecognition = () => {
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      toast({
        title: "Voice Not Supported",
        description: "Your browser doesn't support voice input. Please type your message.",
        variant: "destructive",
      });
      return false;
    }

    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    
    recognition.continuous = false;
    recognition.interimResults = false;
    recognition.lang = 'en-US';

    recognition.onstart = () => {
      setIsListening(true);
      toast({
        title: "Listening...",
        description: "Speak now, I'm listening!",
      });
    };

    recognition.onresult = (event: any) => {
      const transcript = event.results[0][0].transcript;
      setInput(transcript);
      setIsListening(false);
    };

    recognition.onerror = (event: any) => {
      setIsListening(false);
      toast({
        title: "Voice Error",
        description: "Couldn't understand. Please try again or type your message.",
        variant: "destructive",
      });
    };

    recognition.onend = () => {
      setIsListening(false);
    };

    recognitionRef.current = recognition;
    return true;
  };

  const toggleVoiceInput = () => {
    if (!isListening) {
      if (initSpeechRecognition()) {
        recognitionRef.current?.start();
      }
    } else {
      recognitionRef.current?.stop();
      setIsListening(false);
    }
  };

  return (
    <>
      <Dialog open={open} onOpenChange={onOpenChange}>
        <DialogContent className="max-w-2xl max-h-[80vh] flex flex-col">
          <DialogHeader>
            <DialogTitle className="flex items-center gap-2">
              <Bot className="h-5 w-5 text-blue-600" />
              AI Art Assistant
              <div className="flex items-center gap-2 ml-auto">
                <Button
                  variant="ghost"
                  size="sm"
                  onClick={() => {
                    setVoiceEnabled(!voiceEnabled);
                    if (!voiceEnabled) {
                      toast({
                        title: "Voice Output Enabled",
                        description: "I'll speak my responses now!",
                      });
                    } else {
                      window.speechSynthesis.cancel();
                      setIsSpeaking(false);
                    }
                  }}
                  className="h-8 w-8 p-0"
                >
                  {voiceEnabled ? <Volume2 className="h-4 w-4" /> : <VolumeX className="h-4 w-4" />}
                </Button>
                <Badge variant="outline" className={isSpeaking ? "bg-green-50 text-green-700" : ""}>
                  {isSpeaking && 'Speaking...'}
                  {!isSpeaking && currentStep === 'greeting' && 'Ready'}
                  {!isSpeaking && currentStep === 'photo_tips' && 'Guiding'}
                  {!isSpeaking && currentStep === 'uploading' && 'Ready to Upload'}
                  {!isSpeaking && currentStep === 'analyzing' && 'Analyzing...'}
                  {!isSpeaking && currentStep === 'complete' && 'Complete'}
                </Badge>
              </div>
            </DialogTitle>
          </DialogHeader>

          <div className="flex-1 overflow-y-auto space-y-4 p-4">
            {/* Show uploaded files preview */}
            {uploadedFiles.length > 0 && (
              <div className="bg-blue-50 p-3 rounded-lg">
                <div className="flex items-center justify-between mb-2">
                  <span className="text-sm font-medium">Selected Photos ({uploadedFiles.length})</span>
                  <Button
                    size="sm"
                    variant="ghost"
                    onClick={clearFiles}
                    className="h-6 w-6 p-0"
                  >
                    <X className="h-4 w-4" />
                  </Button>
                </div>
                <div className="grid grid-cols-3 gap-2">
                  {uploadedFiles.map((file, index) => (
                    <div key={index} className="relative aspect-square bg-gray-100 rounded">
                      <img
                        src={URL.createObjectURL(file)}
                        alt={`Preview ${index + 1}`}
                        className="w-full h-full object-cover rounded"
                      />
                      <Button
                        size="sm"
                        variant="destructive"
                        className="absolute -top-1 -right-1 h-5 w-5 p-0 rounded-full"
                        onClick={() => {
                          const newFiles = uploadedFiles.filter((_, i) => i !== index);
                          setUploadedFiles(newFiles);
                          if (newFiles.length === 0) {
                            setCurrentStep('uploading');
                          }
                        }}
                      >
                        <X className="h-3 w-3" />
                      </Button>
                    </div>
                  ))}
                </div>
              </div>
            )}

            {messages.map((message) => (
              <div
                key={message.id}
                className={`flex gap-3 ${message.role === 'user' ? 'justify-end' : 'justify-start'}`}
              >
                {message.role === 'assistant' && (
                  <div className="w-8 h-8 rounded-full bg-blue-100 flex items-center justify-center flex-shrink-0">
                    <Bot className="h-4 w-4 text-blue-600" />
                  </div>
                )}
                
                <div className={`max-w-[80%] ${message.role === 'user' ? 'order-first' : ''}`}>
                  <Card className={message.role === 'user' ? 'bg-blue-50' : 'bg-gray-50'}>
                    <CardContent className="p-3">
                      <div className="whitespace-pre-line text-sm">
                        {message.content}
                      </div>
                      
                      {message.actions && message.actions.length > 0 && (
                        <div className="flex flex-wrap gap-2 mt-3">
                          {message.actions.map((action, index) => (
                            <Button
                              key={index}
                              size="sm"
                              variant={action.variant || 'default'}
                              onClick={action.action}
                            >
                              {action.label}
                            </Button>
                          ))}
                        </div>
                      )}
                    </CardContent>
                  </Card>
                  
                  <div className="text-xs text-muted-foreground mt-1 px-2">
                    {message.timestamp.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' })}
                  </div>
                </div>

                {message.role === 'user' && (
                  <div className="w-8 h-8 rounded-full bg-green-100 flex items-center justify-center flex-shrink-0">
                    <User className="h-4 w-4 text-green-600" />
                  </div>
                )}
              </div>
            ))}
            <div ref={messagesEndRef} />
          </div>

          <div className="border-t p-4">
            <div className="flex gap-2">
              <Input
                value={input}
                onChange={(e) => setInput(e.target.value)}
                placeholder="Type your message or question..."
                onKeyPress={(e) => e.key === 'Enter' && handleSendMessage()}
                className="flex-1"
              />
              <Button
                variant="outline"
                size="icon"
                onClick={toggleVoiceInput}
                className={isListening ? 'bg-red-50 text-red-600' : ''}
              >
                {isListening ? <MicOff className="h-4 w-4" /> : <Mic className="h-4 w-4" />}
              </Button>
              <Button onClick={handleSendMessage} disabled={!input.trim()}>
                <Send className="h-4 w-4" />
              </Button>
            </div>
          </div>
        </DialogContent>
      </Dialog>

      <input
        ref={fileInputRef}
        type="file"
        accept="image/*"
        multiple
        className="hidden"
        onChange={handleFileSelect}
      />
    </>
  );
}